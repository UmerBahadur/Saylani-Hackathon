import requests
from bs4 import BeautifulSoup
from datetime import datetime
import json
import pandas as pd
import boto3
import io

s3_client = boto3.client('s3')

BUCKET_NAME = 'data-hackathon-smit-umerbahadur'  # your bucket name

def scrape_cmc_top10():
    url = "https://coinmarketcap.com/"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')

    tbody = soup.find('tbody')
    if not tbody:
        print("No table body found")
        return []

    rows = tbody.find_all('tr')
    if not rows:
        print("No rows found")
        return []

    timestamp = datetime.utcnow()
    timestamp_iso = timestamp.isoformat() + "Z"

    data = []
    for row in rows[:10]:
        cols = row.find_all('td')
        if len(cols) < 10:
            continue
        
        name_symbol_col = cols[2]

        name_tag = name_symbol_col.find('p')
        name = name_tag.text.strip() if name_tag else ''

        p_tags = name_symbol_col.find_all('p')
        if len(p_tags) > 1:
            symbol = p_tags[1].text.strip()
        else:
            small_tag = name_symbol_col.find('small')
            symbol = small_tag.text.strip() if small_tag else ''

        price = cols[3].text.strip()
        change_1h = cols[4].text.strip()
        change_24h = cols[5].text.strip()
        change_7d = cols[6].text.strip()
        market_cap = cols[7].text.strip()
        volume_24h = cols[8].text.strip()
        circulating_supply = cols[9].text.strip()

        data.append({
            "Name": name,
            "Symbol": symbol,
            "Price": price,
            "1h %": change_1h,
            "24h %": change_24h,
            "7d %": change_7d,
            "Market Cap": market_cap,
            "Volume (24h)": volume_24h,
            "Circulating Supply": circulating_supply,
            "Timestamp": timestamp_iso
        })

    return data, timestamp

def lambda_handler(event, context):
    data, timestamp = scrape_cmc_top10()
    if not data:
        return {
            'statusCode': 500,
            'body': json.dumps({'message': 'No data found'})
        }

    # Create a DataFrame and convert to CSV in memory
    df = pd.DataFrame(data)

    csv_buffer = io.StringIO()
    df.to_csv(csv_buffer, index=False)

    # Format S3 key as requested: s3://bucket/raw/CoinMarketCap/YYYY/MM/DD/{HHMM}.csv
    key = timestamp.strftime('raw/CoinMarketCap/%Y/%m/%d/%H%M.csv')

    try:
        s3_client.put_object(Bucket=BUCKET_NAME, Key=key, Body=csv_buffer.getvalue())
        print(f"Saved CSV to s3://{BUCKET_NAME}/{key}")
    except Exception as e:
        print(f"Error uploading to S3: {e}")
        return {
            'statusCode': 500,
            'body': json.dumps({'message': 'Error uploading to S3', 'error': str(e)})
        }

    return {
        'statusCode': 200,
        'body': json.dumps({'message': 'Success', 's3_key': key})
    }
